{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Abrir PDFs.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"Python 3.8.5 64-bit ('3.8.5')","display_name":"Python 3.8.5 64-bit ('3.8.5')","metadata":{"interpreter":{"hash":"aaf48ac79859a89395fd43a81b33890a0deee6a5a92b5cd86726e725c305becd"}}}},"cells":[{"source":["# Data acquisition from .pdf files\n","\n","This notebook acquires data from the dataset2/falencias\n","\n","Requirements:\n","\n","*   textract - Enables easier extraction of text from .pdf files\n","*   pandas - Provides dataframes for storage, and conversion to .csv"],"cell_type":"markdown","metadata":{}},{"source":["The next cells are needed to run the notebook inside the Google Colaboratory platform, with the datasets in Google Drive"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"id":"Fpa6xAMVfCoq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":411},"executionInfo":{"status":"ok","timestamp":1600386299849,"user_tz":180,"elapsed":3234,"user":{"displayName":"Pedro Henrique Barbosa de Almeida","photoUrl":"","userId":"11730038738616894500"}},"outputId":"4158c01e-ecca-4454-f9e7-e25a9889dab9"},"source":["!pip install textract"],"execution_count":null,"outputs":[]},{"source":["Setting up connection to Google Drive"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"id":"m_9pSOhzfG-t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1600386301232,"user_tz":180,"elapsed":765,"user":{"displayName":"Pedro Henrique Barbosa de Almeida","photoUrl":"","userId":"11730038738616894500"}},"outputId":"1aadf26e-ce15-4c42-eb44-b7794bd0e3cf"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# dataset2 location in Google Drive\n","PATH_falencias = '/content/drive/Shared drives/NLP Jurídico - Lab. Ciência de Dados/Dados PDFs falencias'\n","PATH_save = '/content/drive/Shared drives/NLP Jurídico - Lab. Ciência de Dados'"],"execution_count":null,"outputs":[]},{"source":["The next cell is needed to run the notebook locally, with the datasets available in a local disk"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["PATH_falencias = '/run/media/raktanaka/KINGSTON/dataset2/falenciaspdf'\n","PATH_save = '/run/media/raktanaka/KINGSTON'"]},{"cell_type":"code","execution_count":189,"metadata":{},"outputs":[],"source":["import os\n","import csv\n","import textract\n","import unicodedata\n","import re"]},{"cell_type":"code","execution_count":190,"metadata":{},"outputs":[],"source":["def GetPDFData(processo, path_pdf, log_succ, log_fail):\n","\n","    arquivo = os.path.split(path_pdf)[1]\n","    dic = {}\n","\n","    try:\n","        index_ini_parent = arquivo.find('(')\n","        tipo_documento = arquivo[:index_ini_parent-1]\n","        # Normalizes graphic accentuation \n","        tipo_documento = unicodedata.normalize('NFC', tipo_documento)\n","        tipo_documento = tipo_documento.lower()\n","        n_folha_inicio = 0\n","        n_folha_fim = 0\n","        nome_assinador = ''\n","\n","        pag_encontrada = False\n","        nome_do_arquivo = arquivo[index_ini_parent:]\n","\n","        '''\n","        Gets the initial and final page from the file name\n","        '''\n","        # Tries to get what's between two parenthesis (...). If the string \"pag\"\n","        # isn't present, tries to get two more parenthesis (...) in the file name. \n","        # This is crucial because there are filenames like \"Bla (AR) (pag. xxx - xxx).pdf\"\n","\n","        while(not pag_encontrada):\n","            index_ini_parent = nome_do_arquivo.find('(')\n","            index_fim_parent = nome_do_arquivo.find(')')\n","            \n","            # Checks if there're still substrings with \"(...)\"\n","            if index_ini_parent != -1:\n","                # Checks if there's something like \"(pag)\" within the substring\n","                if 'pag' in nome_do_arquivo[index_ini_parent:index_fim_parent]: \n","                    pag_encontrada = True\n","                    # Checks if there're one or two pages in the file name\n","                    index_traco = nome_do_arquivo.find('-')\n","                    if index_traco != -1: \n","                        n_folha_inicio = int(nome_do_arquivo[index_ini_parent+4:index_traco-1])\n","                        n_folha_fim = int(nome_do_arquivo[index_traco+1:index_fim_parent])\n","                    else: \n","                        n_folha_inicio = int(nome_do_arquivo[index_ini_parent+4:index_fim_parent])\n","                        n_folha_fim = int(nome_do_arquivo[index_ini_parent+4:index_fim_parent])\n","            else: \n","                pag_encontrada = True\n","            nome_do_arquivo = nome_do_arquivo[index_fim_parent+1:]\n","\n","        '''\n","        Extracts the string from the PDF\n","        '''\n","        if (len(arquivo) > 4 and arquivo[-4:] == '.pdf'):\n","            text = textract.process(path_pdf)\n","            text = text.decode(\"utf-8\")\n","            text = unicodedata.normalize('NFC', text)\n","            text = text.lower()\n","            text = text.replace('\\n', '')\n","            data_doc = ''\n","\n","            '''\n","            Tries to find the signature date \n","            '''\n","            index_date = text.find(\"protocolado em\")\n","            if index_date != -1:\n","                data_doc = text[index_date+15:index_date+25]\n","            else: \n","                index_date = text.find(\"liberado nos autos em\")\n","                if index_date != -1: \n","                    data_doc = text[index_date+22:index_date+32]\n","            '''\n","            Tries to find who has signed the documento\n","            '''\n","            index_name = text.find(\"assinado digitalmente por\")\n","            if index_name != -1:\n","                index_end_name = text[index_name:].find(',')\n","                nome_assinador = text[index_name+26:index_name+index_end_name]\n","\n","            # Filters the PDF string, removing the stopwords and other garbage. \n","            text = re.sub('(para conferir o original)(.+?)(e código [0-9A-za-z]+\\.)', '', text)\n","            text = re.sub('(este documento é cópia do original).+?(às [0-9]{2}:[0-9]{2} , sob o número [A-Za-z0-9]+\\.)', '', text)\n","            text = re.sub('(este documento é cópia do original).+?(liberado nos autos em [0-9]{2}/[0-9]{2}/[0-9]{4} às [0-9]{2}:[0-9]{2} . )', '', text)\n","\n","        dic = {'n_processo': processo, 'tipo_documento': tipo_documento,\n","                'string': text, 'data_doc': data_doc, 'assinado_por': nome_assinador,\n","                'n_folha_inicio': n_folha_inicio, 'n_folha_fim':n_folha_fim}\n","        #print(arquivo)\n","        #print(processo, tipo_documento, data_doc, n_folha_inicio, n_folha_fim)\n","        log_succ.write(processo + ' ' + arquivo + '\\n')\n","\n","    except: \n","        #print('Ocorreu um problema ao processar o seguinte documento: ')\n","        #print(arquivo)\n","        log_fail.write(processo + ' ' + arquivo + '\\n')\n","        pass\n","\n","    return(dic)\n"]},{"cell_type":"code","execution_count":191,"metadata":{},"outputs":[],"source":["def WalkDirs(root, dirs):\n","\n","    path = os.path.join(root, dirs)\n","    subroot, subdirs, files = next(os.walk(path))\n","    \n","    if subdirs:\n","        for each_dir in subdirs:\n","            subfiles = WalkDirs(subroot, each_dir)\n","            subfiles = [os.path.join(each_dir, f) for f in subfiles]\n","            files.extend(subfiles)\n","\n","    return(files)\n","            \n"]},{"cell_type":"code","execution_count":203,"metadata":{"tags":[]},"outputs":[],"source":["# Files: success and failure logs, and the csv with pdf data\n","log_succ = open(os.path.join(PATH_save, 'pdf_success.log'), 'w')\n","log_fail = open(os.path.join(PATH_save, 'pdf_error.log'), 'w')\n","csv_pdf = open(os.path.join(PATH_save, 'csv_pdf.csv'), 'w')\n","csv_columns = ['n_processo', 'tipo_documento', 'string', 'data_doc', 'assinado_por', 'n_folha_inicio', 'n_folha_fim']\n","writer = csv.DictWriter(csv_pdf, fieldnames=csv_columns)\n","writer.writeheader()\n","\n","# Get all processes = directories\n","root, dirs, files = next(os.walk(PATH_falencias))\n","dirs.sort()\n","\n","for processo in dirs:\n","    p_root, p_dirs, p_files = next(os.walk(os.path.join(root, processo)))\n","    # If has subbdirectories, gets the pdfs inside\n","    if p_dirs:\n","        for each_dir in p_dirs:\n","            # Skips hidden or system directories\n","            if not each_dir.startswith('.') and not each_dir.startswith('System'):\n","                subfiles = WalkDirs(p_root, each_dir)\n","                subfiles = [os.path.join(each_dir, f) for f in subfiles]\n","                p_files.extend(subfiles)\n","\n","    # With the list of all pdfs, starts processing the data\n","    p_files.sort()\n","    for pdf in p_files:\n","        # Skips hidden or system files\n","        if not pdf.startswith('.') and not pdf.startswith('System'):\n","            dic = GetPDFData(processo, os.path.join(p_root, pdf), log_succ, log_fail)\n","            writer.writerow(dic)\n","\n","log_succ.close()\n","log_fail.close()\n","csv_pdf.close()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}