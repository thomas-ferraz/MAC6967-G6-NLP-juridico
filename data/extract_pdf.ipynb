{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Abrir PDFs.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python_defaultSpec_1601410613779","display_name":"Python 3.8.5 64-bit ('3.8.5')","metadata":{"interpreter":{"hash":"e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"}}}},"cells":[{"source":["# Data acquisition from .pdf files\n","\n","This notebook acquires data from the dataset2/falencias\n","\n","Requirements:\n","\n","*   textract - Enables easier extraction of text from .pdf files\n","*   pandas - Provides dataframes for storage, and conversion to .csv"],"cell_type":"markdown","metadata":{}},{"source":["The next cells are needed to run the notebook inside the Google Colaboratory platform, with the datasets in Google Drive"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"id":"Fpa6xAMVfCoq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":411},"executionInfo":{"status":"ok","timestamp":1600386299849,"user_tz":180,"elapsed":3234,"user":{"displayName":"Pedro Henrique Barbosa de Almeida","photoUrl":"","userId":"11730038738616894500"}},"outputId":"4158c01e-ecca-4454-f9e7-e25a9889dab9"},"source":["!pip install textract"],"execution_count":null,"outputs":[]},{"source":["Setting up connection to Google Drive"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"id":"m_9pSOhzfG-t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1600386301232,"user_tz":180,"elapsed":765,"user":{"displayName":"Pedro Henrique Barbosa de Almeida","photoUrl":"","userId":"11730038738616894500"}},"outputId":"1aadf26e-ce15-4c42-eb44-b7794bd0e3cf"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# dataset2 location in Google Drive\n","PATH_falencias = '/content/drive/Shared drives/NLP Jurídico - Lab. Ciência de Dados/Dados PDFs falencias'\n","PATH_save = '/content/drive/Shared drives/NLP Jurídico - Lab. Ciência de Dados'"],"execution_count":null,"outputs":[]},{"source":["The next cell is needed to run the notebook locally, with the datasets available in a local disk"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["PATH_falencias = '/run/media/raktanaka/4387-FFCB/falenciaspdf'\n","PATH_save = '/run/media/raktanaka/4387-FFCB'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import pandas as pd\n","import textract\n","import unicodedata\n","import re"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["df = pd.DataFrame(columns=['n_processo', 'tipo_documento', 'string', 'data_doc', 'assinado_por', 'n_folha_inicio', 'n_folha_fim'])\n","\n","log_succ = open(os.path.join(PATH_save, 'pdf_success.log'), 'w')\n","log_fail = open(os.path.join(PATH_save, 'pdf_error.log'), 'w')\n","\n","processos = os.listdir(PATH_falencias)\n","processos.sort()\n","tot_processos = len(processos)\n","p_counter = 1\n","\n","for processo in processos: # For each action\n","    print('PROCESSO ' + str(p_counter) + '\\\\' + str(tot_processos))\n","    p_counter += 1\n","    PATH_processo = os.path.join(PATH_falencias, processo)\n","    # Needed to remove hidden files/folders in MacOS or Windows\n","    if not processo.startswith('.') or not processo.startswith('System'):\n","        arquivos = [f for f in os.listdir(PATH_processo) if os.path.isfile(os.path.join(PATH_processo, f))]\n","        pastas = [f for f in os.listdir(PATH_processo) if not os.path.isfile(os.path.join(PATH_processo, f))]\n","\n","        arquivos.sort()\n","        pastas.sort()\n","        a_counter = 1\n","        tot_arquivos = len(arquivos)\n","        for arquivo in arquivos:\n","            print('  ARQUIVO ' + str(a_counter) + '\\\\' + str(tot_arquivos))\n","            a_counter += 1\n","            try:\n","                index_ini_parent = arquivo.find('(')\n","                tipo_documento = arquivo[:index_ini_parent-1]\n","                # Normalizes graphic accentuation \n","                tipo_documento = unicodedata.normalize('NFC', tipo_documento)\n","                tipo_documento = tipo_documento.lower()\n","                n_folha_inicio = 0\n","                n_folha_fim = 0\n","                nome_assinador = ''\n","\n","                pag_encontrada = False\n","                nome_do_arquivo = arquivo[index_ini_parent:]\n","\n","                '''\n","                Gets the initial and final page from the file name\n","                '''\n","                # Tries to get what's between two parenthesis (...). If the string \"pag\"\n","                # isn't present, tries to get two more parenthesis (...) in the file name. \n","                # This is crucial because there are filenames like \"Bla (AR) (pag. xxx - xxx).pdf\"\n","\n","                while(not pag_encontrada):\n","                    index_ini_parent = nome_do_arquivo.find('(')\n","                    index_fim_parent = nome_do_arquivo.find(')')\n","                    \n","                    # Checks if there're still substrings with \"(...)\"\n","                    if index_ini_parent != -1:\n","                        # Checks if there's something like \"(pag)\" within the substring\n","                        if 'pag' in nome_do_arquivo[index_ini_parent:index_fim_parent]: \n","                            pag_encontrada = True\n","                            # Checks if there're one or two pages in the file name\n","                            index_traco = nome_do_arquivo.find('-')\n","                            if index_traco != -1: \n","                                n_folha_inicio = int(nome_do_arquivo[index_ini_parent+4:index_traco-1])\n","                                n_folha_fim = int(nome_do_arquivo[index_traco+1:index_fim_parent])\n","                            else: \n","                                n_folha_inicio = int(nome_do_arquivo[index_ini_parent+4:index_fim_parent])\n","                                n_folha_fim = int(nome_do_arquivo[index_ini_parent+4:index_fim_parent])\n","                    else: \n","                        pag_encontrada = True\n","                    nome_do_arquivo = nome_do_arquivo[index_fim_parent+1:]\n","\n","                '''\n","                Extracts the string from the PDF\n","                '''\n","                if (len(arquivo) > 4 and arquivo[-4:] == '.pdf'):\n","                    text = textract.process(PATH_processo + '/' + arquivo)\n","                    text = text.decode(\"utf-8\")\n","                    text = unicodedata.normalize('NFC', text)\n","                    text = text.lower()\n","                    text = text.replace('\\n', '')\n","                    data_doc = ''\n","\n","                    '''\n","                    Tries to find the assignature date \n","                    '''\n","                    index_date = text.find(\"protocolado em\")\n","                    if index_date != -1:\n","                        data_doc = text[index_date+15:index_date+25]\n","                    else: \n","                        index_date = text.find(\"liberado nos autos em\")\n","                        if index_date != -1: \n","                            data_doc = text[index_date+22:index_date+32]\n","                    '''\n","                    Tries to find who has signed the documento\n","                    '''\n","                    index_name = text.find(\"assinado digitalmente por\")\n","                    if index_name != -1:\n","                        index_end_name = text[index_name:].find(',')\n","                        nome_assinador = text[index_name+26:index_name+index_end_name]\n","\n","                    # Filters the PDF string, removing the stopwords and other garbage. \n","                    text = re.sub('(para conferir o original)(.+?)(e código [0-9A-za-z]+\\.)', '', text)\n","                    text = re.sub('(este documento é cópia do original).+?(às [0-9]{2}:[0-9]{2} , sob o número [A-Za-z0-9]+\\.)', '', text)\n","                    text = re.sub('(este documento é cópia do original).+?(liberado nos autos em [0-9]{2}/[0-9]{2}/[0-9]{4} às [0-9]{2}:[0-9]{2} . )', '', text)\n","\n","                df = df.append({'n_processo': processo, 'tipo_documento': tipo_documento,\n","                                'string': text, 'data_doc': data_doc, 'assinado_por': nome_assinador,'n_folha_inicio': n_folha_inicio, \n","                                'n_folha_fim':n_folha_fim}, ignore_index=True)\n","                #print(arquivo)\n","                #print(processo, tipo_documento, data_doc, n_folha_inicio, n_folha_fim)\n","                log_succ.write(processo + ' ' + arquivo + '\\n')\n","            \n","            except: \n","                #print('Ocorreu um problema ao processar o seguinte documento: ')\n","                #print(arquivo)\n","                log_fail.write(processo + ' ' + arquivo + '\\n')\n","                pass\n","    \n","log_succ.close()\n","log_fail.close()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Stores the DataFrame in a csv\n","csv_name = 'dadospdf.csv'\n","csv_file = os.path.join(PATH_save, csv_name)\n","save = open(csv_file, 'w')\n","df.to_csv(save)\n","save.close()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}